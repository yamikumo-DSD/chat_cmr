{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcabab5c-9248-4393-b262-eafc68cd8ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install ipywidgets jupyter-ui-poll\n",
    "#!pip install llama-cpp-python langchain\n",
    "#!pip install style-bert-vits2 alkana\n",
    "#!pip install pandas black\n",
    "#!pip install google-api-python-client selenium beautifulsoup4 pdfplumber\n",
    "#!pip install favicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed8c855-4eab-4fd6-8d95-2149dbff4a81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from warnings import simplefilter\n",
    "ignore_warnings = lambda : simplefilter('ignore')\n",
    "\n",
    "import os\n",
    "import llama_cpp\n",
    "import re\n",
    "import json\n",
    "import threading\n",
    "import asyncio\n",
    "from os import path\n",
    "\n",
    "# For ipywidgets.\n",
    "from IPython.display import clear_output, HTML\n",
    "from ipywidgets import widgets\n",
    "\n",
    "# my libs\n",
    "from lib.infrastructure import ForgetableContext, LlamaCpp, temporal_llama_cache\n",
    "from lib.uis import activate_cancel_ui, wait_for_change\n",
    "from lib.utils import now, mixed2katakana, get, fix_indentation\n",
    "from lib.infrastructure import LlamaInputIDManager\n",
    "\n",
    "# llama-cpp-python\n",
    "from llama_cpp import LlamaDiskCache\n",
    "\n",
    "# style-bert-vits2\n",
    "from style_bert_vits2.nlp import bert_models\n",
    "from style_bert_vits2.constants import Languages\n",
    "from style_bert_vits2.tts_model import TTSModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6071cf24-c40e-4c24-89b2-53dc8f1bd9d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = LlamaCpp(\n",
    "    model_path=\"path/to/your/gguf/file\",\n",
    "    n_gpu_layers=-1,\n",
    "    n_batch=1024,\n",
    "    n_ctx=8192,\n",
    "    use_mlock=True,\n",
    "    verbose=False,\n",
    "    embedding=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cac0c7a-3492-4f8f-b3be-b3ceb80df187",
   "metadata": {},
   "outputs": [],
   "source": [
    "internal_llama = model.model.model\n",
    "def tokenize(text: str):\n",
    "    \"\"\" This function doesn't add bos token. \"\"\"\n",
    "    return internal_llama.tokenize(text.encode(\"utf-8\"), add_bos=False, special=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2ad7d3-d6dc-4a76-8880-dbf77ffefee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Globals.\n",
    "from lib.tools import MyPythonREPL\n",
    "from lib.lang_chain_tools import GoogleSearchOpenable\n",
    "\n",
    "DEFAULT_ASSISTANT_NAME = '„Éü„ÇØ'\n",
    "DEFAULT_USER_NICKNAME = '„Åõ„Çì„Åõ'\n",
    "PYTHON_RUNTIME_NAME = 'Python Runtime'\n",
    "SEARCH_AGENT_NAME = 'Search Agent'\n",
    "\n",
    "MAXLEN = 70 \n",
    "assistant_name = DEFAULT_ASSISTANT_NAME\n",
    "user_nickname = DEFAULT_USER_NICKNAME\n",
    "context = ForgetableContext(maxlen=MAXLEN)\n",
    "py = MyPythonREPL(replace_nl=False, temporal_working_directory='agent_working_dir')\n",
    "login_time_stamp: str = \"\"\n",
    "instructions: str = \"\"\n",
    "\n",
    "# Event loop.\n",
    "loop = asyncio.get_event_loop()\n",
    "\n",
    "# style-bert-vits2\n",
    "tts_model: TTSModel|None = None\n",
    "\n",
    "# Set caches.\n",
    "main_cache = LlamaDiskCache(\".cache/cmr/main_cache\", 2e9)\n",
    "agent_cache = LlamaDiskCache(\".cache/cmr/agent_cache\", 2e9)\n",
    "\n",
    "# Use your own API_KEY and CSE_ID.\n",
    "GOOGLE_API_KEY = \"YOUR_GOOGLE_API_KEY\"\n",
    "GOOGLE_CSE_ID = \"YOUR_GOOGLE_CSE_ID\"\n",
    "google = GoogleSearchOpenable(n_max_results=5, api_key=GOOGLE_API_KEY, cse_id=GOOGLE_CSE_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e7c259-52ad-484d-bfb3-011026834579",
   "metadata": {},
   "outputs": [],
   "source": [
    "internal_llama.cache = main_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc26c39-1644-4ab4-bbb0-d8ef49897e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GUIs.\n",
    "out = widgets.Output()\n",
    "debug = widgets.Output(layout=widgets.Layout(width='600px', height='100px', overflow='scroll'))\n",
    "field = widgets.Textarea(placeholder=f'„É¶„Éº„Ç∂„Éº:', layout=widgets.Layout(width='700px', height='auto'))\n",
    "user_nickname_field = widgets.Text(description='AI->you', value=user_nickname, placeholder='Your nickname', layout=widgets.Layout(width='200px'))\n",
    "assistant_name_field = widgets.Text(description='You->AI', value=assistant_name, placeholder='Assistant name', layout=widgets.Layout(width='200px'))\n",
    "button = widgets.Button(description='üì§', button_style='success', layout=widgets.Layout(width='50px', height='50px'))\n",
    "reset_button = widgets.Button(description='Reset', layout=widgets.Layout(width='120px'))\n",
    "retrieve = widgets.Button(description='Undo', layout=widgets.Layout(width='120px'))\n",
    "create_voice = widgets.Button(description='Synthesize voice', layout=widgets.Layout(width='120px'))\n",
    "buttons = [button, reset_button, retrieve, create_voice]\n",
    "voice_player = widgets.Output()\n",
    "dropdown: widgets.Dropdown|None = None\n",
    "voice_length = widgets.FloatSlider(value=1.15, min=0.5, max=2.0, step=0.05)\n",
    "\n",
    "def get_bigger(args):        \n",
    "    nls = field.value.count('\\n')\n",
    "    field.rows = nls + 1 if nls >= 1 else 2\n",
    "field.observe(get_bigger, 'value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7b25fa-acdf-4ba4-9522-ea8979e90ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_buttons(disabled: bool) -> None:\n",
    "    global buttons\n",
    "    for b in buttons:\n",
    "        b.disabled = disabled\n",
    "\n",
    "def disable_uis(func):\n",
    "    from functools import wraps\n",
    "    @wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        set_buttons(disabled=True)\n",
    "        set_guessing_image(True)\n",
    "        result = func(*args, **kwargs)\n",
    "        set_guessing_image(False)\n",
    "        set_buttons(disabled=False)\n",
    "        return result\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f542ecf0-38fd-4648-8ff0-7a96fe714770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TTS model loader\n",
    "\n",
    "\n",
    "def is_tts_model_dir(path):\n",
    "    if not os.path.isdir(path):\n",
    "        return False\n",
    "    files_to_check = [\n",
    "        f\"{os.path.basename(path)}.safetensors\",\n",
    "        \"config.json\",\n",
    "        \"style_vectors.npy\",\n",
    "    ]\n",
    "    folder_files = os.listdir(path)\n",
    "    return all(file in folder_files for file in files_to_check)\n",
    "\n",
    "\n",
    "\n",
    "@debug.capture()\n",
    "def load_tts_models(model_path):\n",
    "    import gc; gc.collect()\n",
    "    \n",
    "    bert_models.load_model(Languages.JP, \"ku-nlp/deberta-v2-large-japanese-char-wwm\")\n",
    "    bert_models.load_tokenizer(Languages.JP, \"ku-nlp/deberta-v2-large-japanese-char-wwm\")\n",
    "    \n",
    "    return TTSModel(\n",
    "        model_path=os.path.join(model_path, f\"{os.path.basename(model_path)}.safetensors\"),\n",
    "        config_path=os.path.join(model_path, \"config.json\"),\n",
    "        style_vec_path=os.path.join(model_path, \"style_vectors.npy\"),\n",
    "        device=\"cpu\"\n",
    "    )\n",
    "\n",
    "ASSET_ROOT = \"style_bert_vits2_models\"\n",
    "\n",
    "async def capture_model_selection_change():\n",
    "    global tts_model\n",
    "    while True:\n",
    "        selected = await wait_for_change(dropdown, \"value\")\n",
    "        tts_model = load_tts_models(os.path.join(ASSET_ROOT, selected))\n",
    "        debug.append_stdout(f\"tts_model({selected}) loaded.\\n\")\n",
    "\n",
    "tts_model_names = [item for item in os.listdir(ASSET_ROOT) if is_tts_model_dir(os.path.join(ASSET_ROOT, item))]\n",
    "if len(tts_model_names) != 0:\n",
    "    tts_model = load_tts_models(os.path.join(ASSET_ROOT, tts_model_names[0]))\n",
    "dropdown = widgets.Dropdown(description=\"TTS model\", options=tts_model_names, value=tts_model_names[0]) if len(tts_model_names) != 0 else widgets.Dropdown(description=\"TTS model\", options=[])\n",
    "task = loop.create_task(capture_model_selection_change())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da014e06-8893-48f8-8b16-5b761bb23210",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reload_instruction(instruction_file_path: str):\n",
    "    instructions = \"\"\n",
    "    with open(instruction_file_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        instructions = ''.join(lines)\n",
    "    return instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78e503b-00ac-47ab-959f-a78a9d59b3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_log():\n",
    "    import datetime\n",
    "    global context\n",
    "    filename = str(datetime.datetime.now()).replace(' ', '_') + '.txt'\n",
    "    with open(f'log/{filename}', 'w') as f:\n",
    "       f.writelines(str(context))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8dd20d-0425-4212-a0eb-688a0e54a6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_description = {\n",
    "    \"google\": \"Ê§úÁ¥¢„ÉØ„Éº„Éâ„ÇíÂºïÊï∞„Å®„Åó„Å¶googleÊ§úÁ¥¢„ÇíË°å„ÅÜ„ÄÇ„É™„Ç¢„É´„Çø„Ç§„É†ÊÉÖÂ†±„ÇíÂæó„ÇãÂ†¥Âêà„Å´„ÅØÂøÖ„Åö„Åì„ÅÆ„ÉÑ„Éº„É´„Çí‰ΩøÁî®„Åô„Çã„Åì„Å®„ÄÇ\",\n",
    "    \"python\": \"Python„Ç≥„Éº„Éâ„ÇíË®òËø∞„ÉªÂÆüË°å„Åó„Åæ„Åô„ÄÇ„Ç≥„Éº„Éâ„ÅØÈÅ©ÂÆúÊîπË°å„Åô„Çã„Åì„Å®„ÄÇÂ§âÊï∞„ÇÑÈñ¢Êï∞„ÅØ„Çª„ÉÉ„Ç∑„Éß„É≥ÂÜÖ„ÅßÂÖ±Êúâ„Åï„Çå„Åæ„Åô„ÄÇÁµêÊûú„ÅØÂøÖ„Åöprint„ÅÇ„Çã„ÅÑ„ÅØplt.show()„ÅßÂá∫Âäõ„Åô„Çã„Åì„Å®„ÄÇ\",\n",
    "}\n",
    "available_tools = list(tool_description.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af74b50-de10-4906-b61c-6d7270448b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt formatting.\n",
    "# This section highly depends on the prompt template of the instruction model.\n",
    "\n",
    "instructions = reload_instruction(\"prompt_gen_13_cmr.txt\")\n",
    "\n",
    "def item2str(item) -> str:\n",
    "    role = get(item, 'role')\n",
    "    content = get(item, 'content')\n",
    "    code = get(item, 'code')\n",
    "    code_output = get(item, 'code_output')\n",
    "    search_query = get(item, 'search_query')\n",
    "    search_result = get(item, 'search_result')\n",
    "    references = get(item, 'references')\n",
    "\n",
    "    item_text = content\n",
    "\n",
    "    def add_block(block_name, block_content) -> str:\n",
    "        return f\"\"\"\n",
    "```{block_name}\n",
    "{block_content}\n",
    "```\n",
    "\"\"\"\n",
    "    \n",
    "    if code: item_text += add_block(\"python\", code)\n",
    "    if code_output: item_text += add_block(\"output\", code_output)\n",
    "    if search_query: item_text += add_block(\"google\", search_query)\n",
    "    if search_result: item_text += add_block(\"result\", search_result)\n",
    "\n",
    "    # According to the document, tool results should be in <|SYSTEM TOKEN|>\n",
    "    # https://docs.cohere.com/docs/prompting-command-r\n",
    "    if role == assistant_name: return f\"<|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>{item_text}<|END_OF_TURN_TOKEN|>\"\n",
    "    elif role == \"„É¶„Éº„Ç∂„Éº\": return f\"<|START_OF_TURN_TOKEN|><|USER_TOKEN|>{item_text}<|END_OF_TURN_TOKEN|>\"\n",
    "    elif role == \"„Ç∑„Çπ„ÉÜ„É†\": return f\"<|START_OF_TURN_TOKEN|><|SYSTEM_TOKEN|>{item_text}<|END_OF_TURN_TOKEN|>\"\n",
    "    elif role == PYTHON_RUNTIME_NAME: return f\"<|START_OF_TURN_TOKEN|><|SYSTEM_TOKEN|>{item_text}<|END_OF_TURN_TOKEN|>\"\n",
    "    elif role == SEARCH_AGENT_NAME: return f\"<|START_OF_TURN_TOKEN|><|SYSTEM_TOKEN|>{item_text}<|END_OF_TURN_TOKEN|>\"\n",
    "    else: return f\"<|START_OF_TURN_TOKEN|>{item_text}<|END_OF_TURN_TOKEN|>\"\n",
    "\n",
    "\n",
    "\n",
    "def ctx2str(context, skip: int = 0) -> str:\n",
    "    \"\"\"ignore front items of number specified by 'skip'\"\"\"\n",
    "    text = \"\"\n",
    "    for item in context.context()[skip:]:\n",
    "        text += item2str(item)\n",
    "    return text\n",
    "\n",
    "\n",
    "def compile_instruction(instructions):\n",
    "    return instructions.format(\n",
    "        now=login_time_stamp, \n",
    "        assistant=assistant_name, \n",
    "        user_nickname=user_nickname,\n",
    "        tool_names=available_tools,\n",
    "        tool_description='\\n'.join([f\"{name}: {description}\" for name, description in tool_description.items()]),\n",
    "    )\n",
    "    \n",
    "\n",
    "def make_ppt(\n",
    "    instructions: str, \n",
    "    context,\n",
    "    skip: int = 0,\n",
    ") -> str:\n",
    "    # llama_cpp's tokenizer seems to add bos token automatically?\n",
    "    # https://gist.github.com/kohya-ss/37f4c5ef8171cbb2b6cc1f4fd7999b89\n",
    "    # instructions = \"<BOS_TOKEN>\" + instructions\n",
    "    return compile_instruction(instructions) + ctx2str(context, skip) + \"<|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c51affe-1021-4400-826f-590292fc4d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assistant_speaks(text) -> None:\n",
    "    global tts_model\n",
    "\n",
    "    if tts_model is None:\n",
    "        return\n",
    "    \n",
    "    def replace_text(text, replacement_dict):\n",
    "        for key, value in replacement_dict.items():\n",
    "            text = text.replace(key, value)\n",
    "        return text\n",
    "    \n",
    "    text = mixed2katakana(text)\n",
    "    text = re.sub(r'[(Ôºà].*?[)Ôºâ]', '„ÄÄ', text)\n",
    "\n",
    "    text = replace_text(text, {\n",
    "        '„Åà„Å∏„Å∏': '„Åà„Å∏„Å£',\n",
    "        'ÊêæÁ≤æ': '„Åï„Åè„Åõ„ÅÑ',\n",
    "        'Ë®Ä„Å£„Å¶': '„ÅÑ„Å£„Å¶',\n",
    "        '‚ÑÉ': 'Â∫¶',\n",
    "        '„Åä„Åæ‚óØ„Åì': '„Åä„Åæ„Çì„Åì',\n",
    "        '„Åä„Åæ‚óØ„Åì': '„Åä„Åæ„Çì„Åì',\n",
    "        'kg': '„Ç≠„É≠',\n",
    "        '‚ô™': '„ÄÇ',\n",
    "        'Ôºö': '„ÄÇ',\n",
    "        ':': '„ÄÇ',\n",
    "        'Ë∫´‰Ωì': '„Åã„Çâ„Å†',\n",
    "    })\n",
    "    \n",
    "\n",
    "    try:\n",
    "        from IPython.display import Audio\n",
    "        if len(text) > 0:\n",
    "            with debug: sr, wav = tts_model.infer(text, length=voice_length.value)\n",
    "        else:\n",
    "            return\n",
    "        audio = Audio(wav, rate=sr, autoplay=False)\n",
    "        voice_player.clear_output(wait=True)\n",
    "        with voice_player: display(audio)\n",
    "    except BaseException as e:\n",
    "        with debug: print(e)\n",
    "            \n",
    "@disable_uis\n",
    "def create_voice_action(sender=None):\n",
    "    try:\n",
    "        text = get(context.history()[-1], \"content\")\n",
    "        assistant_speaks(text)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7b5897-1729-4071-b334-6b3d92a3e8e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Web browsing agent.\n",
    "\n",
    "ignore_warnings()\n",
    "\n",
    "from langchain.tools import Tool\n",
    "from lib.lang_chain_agent_cmr import create_agent_executor\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"google\", func=google.set,\n",
    "        description=\"WebÊ§úÁ¥¢„ÇíË°å„ÅÜ„ÉÑ„Éº„É´„Åß„Åô„ÄÇAction Input„Å´Ê§úÁ¥¢„ÉØ„Éº„Éâ„ÇíÊåáÂÆö„Åó„Åæ„Åô„ÄÇÊ§úÁ¥¢Âæå„ÅØselect„ÅßÂêÑË®ò‰∫ã„ÇíÈñã„Åè‰∫ã„Åå„Åß„Åç„Åæ„Åô„ÄÇ\", \n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"select\", func=google.open,\n",
    "        description=\"google„ÅßÊ§úÁ¥¢„Åó„ÅüÁï™Âè∑„ÇíAction Input„Å´[Ê§úÁ¥¢ÁµêÊûú1]„ÅÆ„Çà„ÅÜ„Å´ÊåáÂÆö„Åó„Å¶„ÄÅ„Éö„Éº„Ç∏„ÇíÈñã„Åç„Åæ„Åô(‰∏ÄÂ∫¶„Å´Èñã„Åë„Çã„ÅÆ„ÅØ„Å≤„Å®„Å§„ÅÆ„Åø)„ÄÇ\", \n",
    "    ),\n",
    "]\n",
    "\n",
    "agent_executor = create_agent_executor(\n",
    "    model, \n",
    "    tools, \n",
    "    max_iterations=8,\n",
    "    return_intermediate_steps=True,\n",
    "    model_kwargs={'temperature': 0.1, 'max_tokens': 1500},\n",
    ")\n",
    "\n",
    "@temporal_llama_cache(internal_llama, agent_cache)\n",
    "def exec_agent(model, request: str) -> tuple:\n",
    "    global google, agent_executor\n",
    "    def cleanup_agent_output(text: str) -> str:\n",
    "        return text.split('Question')[0].split('Thought')[0].strip()\n",
    "    \n",
    "    google.unset()\n",
    "    response = agent_executor.invoke(request)\n",
    "    output = cleanup_agent_output(response['output'])\n",
    "    ref = google.references()\n",
    "    return output, ref\n",
    "\n",
    "def search_agent(search_query: str):\n",
    "    return exec_agent(\n",
    "        model, \n",
    "        f'\"{search_query}\"„ÅßÊ§úÁ¥¢„Åó„Å¶„Åß„Åç„Çã„Å†„ÅëÂÖ∑‰ΩìÁöÑ„Å´ÂÜÖÂÆπ„Çí„Åæ„Å®„ÇÅ„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇÊ§úÁ¥¢„ÉØ„Éº„Éâ„ÅØÊåáÁ§∫ÈÄö„Çä„Å®„Åó„ÄÅÂ§âÊõ¥„Åó„Å¶„ÅØ„ÅÑ„Åë„Åæ„Åõ„Çì„ÄÇ„Åµ„Åü„Å§„ÅØÊ§úÁ¥¢ÁµêÊûú„ÇíÈñã„ÅçÂÜÖÂÆπ„ÇíÁ¢∫Ë™ç„Åô„Çã„Åì„Å®„ÄÇ'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88b6aed-48f4-4597-bb6d-e9e3b95202fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_to_html(context) -> str:\n",
    "    def embed_image_to_tag(image_binary) -> str:\n",
    "        import base64\n",
    "        encoded_image = base64.b64encode(image_binary).decode('utf-8')\n",
    "        html_image_tag = f'<img src=\"data:image/jpeg;base64,{encoded_image}\" />'\n",
    "        return html_image_tag\n",
    "\n",
    "    def replace_charref(text) -> str:\n",
    "        return text.replace('<', '&lt;').replace('>', '&gt;').replace(' ', '&nbsp;')\n",
    "        \n",
    "    def convert_markdown_table_to_html(text):\n",
    "        # Regex to capture Markdown tables\n",
    "        table_pattern = r\"(\\|.*\\|[\\r\\n]+\\|[-|: ]*\\|[\\r\\n]+(\\|.*\\|[\\r\\n]*)+)\"\n",
    "        html_output = text\n",
    "    \n",
    "        # Find all Markdown tables in the text\n",
    "        tables = re.findall(table_pattern, text)\n",
    "        for table in tables:\n",
    "            # Extract the table (removing potential tuple match from groups in regex)\n",
    "            table = table[0]\n",
    "            lines = table.strip().split('\\n')\n",
    "            header = lines[0]\n",
    "            rows = lines[2:]  # Skip the separator line\n",
    "    \n",
    "            # Start converting to HTML\n",
    "            html_table = '<table>'\n",
    "            html_table += '<tr>' + ''.join(f'<th>{col.strip()}</th>' for col in header.split('|') if col.strip()) + '</tr>'\n",
    "            for row in rows:\n",
    "                html_table += '<tr>' + ''.join(f'<td>{col.strip()}</td>' for col in row.split('|') if col.strip()) + '</tr>'\n",
    "            html_table += '</table>'\n",
    "    \n",
    "            # Replace the Markdown table with HTML table in the output\n",
    "            html_output = html_output.replace(table, html_table)\n",
    "    \n",
    "        return html_output\n",
    "\n",
    "    \n",
    "    messages: list[str] = []\n",
    "    for message in context.history():\n",
    "        role = message['role']\n",
    "        content = message['content']\n",
    "\n",
    "        name: str\n",
    "        text: str\n",
    "        text_template = \"\"\"<div style=\"background-color: {color}; word-wrap: break-word; color: black; padding: 10px; border-radius: 20px;\">{content}</div>\"\"\"\n",
    "        \n",
    "        if role == '„É¶„Éº„Ç∂„Éº':\n",
    "            content = replace_charref(content)\n",
    "            content = content.replace('\\n', '</br>')\n",
    "            text = text_template.format(content=content, color='#BBFFBB')\n",
    "            name = '<font color=#888888>„É¶„Éº„Ç∂„Éº</font>'\n",
    "        else:\n",
    "            text = replace_charref(content)\n",
    "            text = convert_markdown_table_to_html(content)\n",
    "\n",
    "            references = get(message, 'references')\n",
    "            code = get(message, 'code')\n",
    "            code_output = get(message, 'code_output')\n",
    "            image_output = get(message, 'image_output')\n",
    "            search_result = get(message, 'search_result')\n",
    "            search_query = get(message, 'search_query')\n",
    "\n",
    "            header = lambda text: f'<div style=\"background-color: #999999; color: black;\">{text}</div>'\n",
    "            if search_query:\n",
    "                text += header(\"Google\")\n",
    "                text += '<div style=\"background-color: #FFFFFF; color: black;\">' + search_query + '</div>'\n",
    "            if search_result:\n",
    "                text += header(\"Ê§úÁ¥¢ÁµêÊûú\")\n",
    "                text += '<div style=\"background-color: #FFFFFF; color: black;\">' + search_result + '</div>'\n",
    "            if references:\n",
    "                text += header(\"ÂèÇËÄÉ\")\n",
    "                text += '<div style=\"background-color: #FFFFFF; color: black;\">' + '\\n'.join([f'‚úÖ<a href=\"{url}\">Ô∏é{url[:50]}...</a>' for url in references]) + '</div>'\n",
    "            if code:\n",
    "                text += header(\"Python\")\n",
    "                text += '<pre><code>' + code + '</code></pre>'\n",
    "            if code_output:\n",
    "                text += header('Output')\n",
    "                text += '<pre><code>' + code_output + '</code></pre>'\n",
    "            if image_output:\n",
    "                text += '</br>' + embed_image_to_tag(image_binary=image_output) + '</br>'\n",
    "\n",
    "            # Other code blocks.\n",
    "            regex = re.compile(r'```(\\w+)?[ \\n](.*?)\\n?```', re.DOTALL)\n",
    "            text = re.sub(\n",
    "                regex, \n",
    "                r'<div style=\"background-color: #999999; color: black;\">\\1</div><pre><code>\\2</code></pre>', \n",
    "                text\n",
    "            )\n",
    "            text = re.sub(r\"`([^`]+?)`\", r'<code>\\1</code>', text) # inline code.\n",
    "            \n",
    "            \n",
    "            text = text.replace('\\n', '</br>')\n",
    "            text = text_template.format(content=text, color='#FFEEBB')\n",
    "            name = f'<font color=#888888><div style=\"text-align:right\">{role}</div></font>'\n",
    "        \n",
    "        messages.append(f'{name}{text}')\n",
    "        \n",
    "    return ''.join(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a8ca55-49b7-4807-a983-9f052bcc4dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_context():\n",
    "    global context\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    html_text = f\"\"\"<!DOCTYPE html>\n",
    "<html>\n",
    "\n",
    "<head>\n",
    "  <meta charset=\"utf-8\" />\n",
    "  <style>\n",
    "    #wrapper {{\n",
    "      display: flex;\n",
    "      flex-direction: column-reverse;\n",
    "      height: 1300px;\n",
    "      width: 800px;\n",
    "      overflow-y: scroll;\n",
    "    }}\n",
    "\n",
    "    /* Custom Scrollbar CSS */\n",
    "    #wrapper::-webkit-scrollbar {{\n",
    "      width: 10px;\n",
    "    }}\n",
    "\n",
    "    #wrapper::-webkit-scrollbar-track {{\n",
    "      background: #f1f1f1;\n",
    "    }}\n",
    "\n",
    "    #wrapper::-webkit-scrollbar-thumb {{\n",
    "      background: #888;\n",
    "    }}\n",
    "\n",
    "    #wrapper::-webkit-scrollbar-thumb:hover {{\n",
    "      background: #555;\n",
    "    }}\n",
    "    \n",
    "  </style>\n",
    "</head>\n",
    "\n",
    "<body>\n",
    "    <div style=\"display: flex; align-items: flex-end;\">\n",
    "      <div id=\"wrapper\">\n",
    "        <div id=\"contents\">\n",
    "    {format_to_html(context)}\n",
    "        </div>\n",
    "      </div>\n",
    "    </div>\n",
    "</body>\n",
    "\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "    display(HTML(html_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cd38fd-d984-4caf-b8ae-56f0eee6cf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "guessing_image: widgets.Image\n",
    "\n",
    "with open('guessing.gif', 'rb') as f:\n",
    "    guessing_image = widgets.Image(value=f.read(), width=50, height=50)\n",
    "\n",
    "def set_guessing_image(show: bool) -> None:\n",
    "    global guessing_image\n",
    "    with open('guessing.gif' if show else 'empty.png', 'rb') as f:\n",
    "        guessing_image.value = f.read() \n",
    "        guessing_image.width = 50\n",
    "        guessing_image.height = 50\n",
    "\n",
    "set_guessing_image(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96546328-7fa7-4fa8-9e6e-5a0b4a441bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize(sender=None) -> None:\n",
    "    global context, field, assistant_name_field, user_nickname_field, login_time_stamp\n",
    "\n",
    "    context.reset()\n",
    "    field.value = ''\n",
    "    user_nickname_field.disabled = False\n",
    "    assistant_name_field.disabled = False\n",
    "    login_time_stamp = now()\n",
    "    \n",
    "    with out:\n",
    "        print_context()\n",
    "\n",
    "    from IPython.display import Audio\n",
    "    voice_player.clear_output(wait=True)\n",
    "    with voice_player:\n",
    "        display(Audio(b''))\n",
    "\n",
    "initialize()\n",
    "\n",
    "def submit_names_action(sender=None) -> None:\n",
    "    global user_nickname, user_nickname_field, assistant_name, assistant_name_field\n",
    "\n",
    "    user_nickname = user_nickname_field.value\n",
    "    assistant_name = assistant_name_field.value\n",
    "    user_nickname_field.disabled = True\n",
    "    assistant_name_field.disabled = True\n",
    "\n",
    "@out.capture()\n",
    "def retrieve_latest_input(sender = None):\n",
    "    global field, context\n",
    "\n",
    "    if len(context) <= 0:\n",
    "        field.value = ''\n",
    "        print_context()\n",
    "        return\n",
    "\n",
    "    last_item = context.force_pop_front(stringize=False)\n",
    "    if last_item['role'] == '„É¶„Éº„Ç∂„Éº':\n",
    "        field.value = last_item['content']\n",
    "    print_context()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e7adfb-b249-48e4-8089-ad4b115b1a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def force_save_state():\n",
    "    global internal_llama\n",
    "    prompt = make_ppt(instructions, context)\n",
    "    prompt_tokens = ((internal_llama.tokenize(prompt.encode(\"utf-8\"), special=True)))\n",
    "    #\n",
    "    # save to main_cache\n",
    "    # using prompt_tokens(+completion_tokens) as key of the cache depends on implementation of llama_cpp's _create_complesion.\n",
    "    # The code: https://github.com/abetlen/llama-cpp-python/blob/main/llama_cpp/llama.py#L954 \n",
    "    #\n",
    "    internal_llama.cache[prompt_tokens] = internal_llama.save_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a363299d-8084-4800-ab11-623761e4e87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_stream(additional_stop_tokens: list[str] = []):\n",
    "    global model, instructions, context\n",
    "\n",
    "    prompt = make_ppt(instructions, context)\n",
    "    \n",
    "    streamer = model.stream(\n",
    "        input=prompt,\n",
    "        temperature=0.2,\n",
    "        max_tokens=1500,\n",
    "        stop=additional_stop_tokens\n",
    "    )\n",
    "\n",
    "    pattern = re.compile(\n",
    "        r'(.*?```\\n?({tools}).*?```)'.format(tools='|'.join(available_tools)), \n",
    "        re.DOTALL\n",
    "    )\n",
    "\n",
    "    output = ''\n",
    "    for token in streamer:\n",
    "        output += token\n",
    "        \n",
    "        match = re.search(pattern, output)\n",
    "        if match:\n",
    "            output = match.group(1)\n",
    "            yield output\n",
    "            # Because of break, token generation doesn't complete properly.\n",
    "            # The inproper interruption results in no activation of diskcache saving that normally happens after completion.\n",
    "            # So, we need to add code to force saving LlamaState.\n",
    "            force_save_state()\n",
    "            break \n",
    "        else:\n",
    "            yield output.strip()\n",
    "        \n",
    "        \n",
    "\n",
    "def predict_stream_with_display(additional_stop_tokens: list[str] = []):\n",
    "    with debug:\n",
    "        for output in predict_stream(additional_stop_tokens):\n",
    "            context.push_message(assistant_name, output)\n",
    "            with out: print_context()\n",
    "            context.force_pop_front()\n",
    "            \n",
    "    context.push_message(assistant_name, output)\n",
    "    with out: print_context()\n",
    "    context.force_pop_front()\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb718b3-29cc-4385-af56-9214ae3236bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def push_context(item, auto_shift_kv: bool):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        item: new item to push.\n",
    "        auto_shift_kv(bool): if true, shift KV-Cache and input_id if needed.\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    from lib.infrastructure import kv_cache_seq_ltrim\n",
    "    \n",
    "    if not auto_shift_kv or len(context) < MAXLEN:\n",
    "        context.push(item)\n",
    "        return\n",
    "\n",
    "    # Context shifting.\n",
    "    oldest_item = context.context(stringize=False)[0]\n",
    "    # This should be placed outside of this function since this is static until instructions reloaded.\n",
    "    n_sys_ppt_tokens = len(tokenize(compile_instruction(instructions))) + 1 # +1 for bos token.\n",
    "    n_oldest_ctx_tokens = len(tokenize(item2str(oldest_item)))\n",
    "    kv_cache_seq_ltrim(\n",
    "        model=internal_llama, \n",
    "        n_keep=n_sys_ppt_tokens,\n",
    "        n_discard=n_oldest_ctx_tokens,\n",
    "    )\n",
    "    context.push(item)\n",
    "    with debug:\n",
    "        print(f\"{n_oldest_ctx_tokens} tokens discarded from position {n_sys_ppt_tokens}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4554cb9b-b3ae-4a67-8d0c-46e522f7be5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def message_chain(reply):\n",
    "    global assistant_name, model, context\n",
    "    push_context({\"role\": assistant_name, \"content\": reply}, auto_shift_kv=True)\n",
    "    with out: print_context()\n",
    "\n",
    "\n",
    "def python_chain(python_code):\n",
    "\n",
    "    # Reformat code.\n",
    "    import black\n",
    "    python_code = fix_indentation(python_code)\n",
    "    try: python_code = black.format_str(python_code, mode=black.Mode())\n",
    "    except: pass\n",
    "\n",
    "    # Add re-formatted code to the latest assistants' content.\n",
    "    last_item = context.force_pop_front(stringize=False)\n",
    "    last_item['code'] = python_code\n",
    "    push_context(last_item, auto_shift_kv=False)\n",
    "    with out: print_context()\n",
    "    \n",
    "    # Run code.\n",
    "    py.unset(keep_locals=True)\n",
    "    py.run(python_code)\n",
    "    _, code_output, image_output = py.result()\n",
    "\n",
    "    # Register into context.\n",
    "    push_context({\n",
    "        \"role\": PYTHON_RUNTIME_NAME,\n",
    "        \"content\": \"\",\n",
    "        \"code_output\": code_output if code_output else \"Empty stdout/stderr.\",\n",
    "        \"image_output\": image_output,\n",
    "    }, auto_shift_kv=True)\n",
    "    with out: print_context()\n",
    "\n",
    "    # Add reaction to the execution results.\n",
    "    reply = predict_stream_with_display(additional_stop_tokens=[\"```\"])\n",
    "    push_context({\"role\": assistant_name, \"content\": reply}, auto_shift_kv=True)\n",
    "    with out: print_context()\n",
    "\n",
    "\n",
    "\n",
    "def search_chain(search_query):\n",
    "    \n",
    "    # Show confirmation of search to the user.\n",
    "    last_item = context.force_pop_front(stringize=False)\n",
    "    last_item['search_query'] = search_query\n",
    "    push_context(last_item, auto_shift_kv=False)\n",
    "    with out: print_context()\n",
    "    with out: cancel = activate_cancel_ui(wait_sec=10)\n",
    "    if cancel:\n",
    "        retrieve_latest_input()\n",
    "        return\n",
    "    \n",
    "    # Invoke search agent.\n",
    "    with out: print_context()\n",
    "    with debug: search_result, referred_urls = search_agent(search_query)\n",
    "\n",
    "    # Register into context.\n",
    "    push_context({\n",
    "        \"role\": SEARCH_AGENT_NAME,\n",
    "        \"content\": \"\",\n",
    "        \"search_result\": search_result,\n",
    "        \"references\": referred_urls,\n",
    "    }, auto_shift_kv=True)\n",
    "    with out: print_context()\n",
    "    \n",
    "    # Add reaction to the search results.\n",
    "    reply = predict_stream_with_display(additional_stop_tokens=[\"```\"])\n",
    "    push_context({\"role\": assistant_name, \"content\": reply}, auto_shift_kv=True)\n",
    "    with out: print_context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df533939-2566-4e73-ae24-f936d65bf9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main loop.\n",
    "@disable_uis\n",
    "def main(sender=None) -> None:\n",
    "    global  context, field, submit_names\n",
    "\n",
    "    submit_names_action()\n",
    "\n",
    "    user_message = field.value\n",
    "    if user_message != '':\n",
    "        field.value = ''\n",
    "        push_context({\"role\": \"„É¶„Éº„Ç∂„Éº\", \"content\": user_message}, auto_shift_kv=True)\n",
    "    with out: print_context()\n",
    "        \n",
    "    output = predict_stream_with_display()\n",
    "\n",
    "    # Parse tool.\n",
    "    regex = re.compile(\n",
    "        r'```\\n?({tools})(.*)```'.format(tools='|'.join(available_tools)), \n",
    "        re.DOTALL\n",
    "    )\n",
    "    tool = re.search(regex, output)\n",
    "\n",
    "    # Remove tool tags.\n",
    "    cleaned_output = re.sub(regex, '', output).rstrip()\n",
    "    message_chain(cleaned_output)\n",
    "    \n",
    "    # Passing to extra chain.\n",
    "    if tool:\n",
    "        tool_type, tool_input = tool.group(1), tool.group(2).strip()\n",
    "        {\n",
    "            'python': python_chain,\n",
    "            'google': search_chain,\n",
    "        }[tool_type](tool_input)\n",
    "\n",
    "    export_log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3547323b-eed7-43dd-973f-812718ecf408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define UI actions.\n",
    "button.on_click(main)\n",
    "reset_button.on_click(initialize)\n",
    "retrieve.on_click(retrieve_latest_input)\n",
    "create_voice.on_click(create_voice_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9aae6c7-1574-4a98-892d-86eadd19773a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_guis() -> None:\n",
    "    html = \"\"\"<h2>{default_name}„Å°„ÇÉ„Çì„Å®„Åä„Åó„ÇÉ„Åπ„Çä!(‰ªÆ)</h2>\n",
    "„Åä„Åó„ÇÉ„Åπ„Çä„ÇÑ„Ç¶„Çß„ÉñÊ§úÁ¥¢„ÉªPythonÂÆüË°å„ÇíÂà©Áî®„Åó„ÅüQ&A„Åå„Åß„Åç„Åæ„Åô„ÄÇ</br>\n",
    "agent_working_dir: PythonÂÆüË°åÊôÇ„ÅÆ„ÉØ„Éº„Ç≠„É≥„Ç∞„Éá„Ç£„É¨„ÇØ„Éà„É™„ÄÇ</br>\n",
    "style_bert_vits2_models: TTS„É¢„Éá„É´„ÇíÂÖ•„Çå„Çã„Éá„Ç£„É¨„ÇØ„Éà„É™„ÄÇ</br>\n",
    "(„É¢„Éá„É´„ÅÆ„ÅÇ„Çã„Çµ„Éñ„Éá„Ç£„É¨„ÇØ„Éà„É™Âêç„Å®.safetensors„ÅÆÂêçÂâç„ÅØ‰∏ÄËá¥„Åó„Å¶„ÅÑ„ÇãÂøÖË¶Å„Åå„ÅÇ„Çä„Åæ„Åô)</br>\n",
    "</br>\n",
    "\"\"\".format(default_name=DEFAULT_ASSISTANT_NAME)\n",
    "    HBox = widgets.HBox\n",
    "    display(\n",
    "        HTML(html),\n",
    "        HBox([user_nickname_field, assistant_name_field]),\n",
    "        out,\n",
    "        HBox([field, button, guessing_image]),\n",
    "        HBox([retrieve, reset_button]),\n",
    "        HTML(\"<br>\"),\n",
    "        HBox([dropdown, voice_length]),\n",
    "        create_voice,\n",
    "        voice_player,\n",
    "#        debug,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabea719-a638-4107-be1f-bfa26321fbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore_warnings()\n",
    "show_guis()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama2-clone",
   "language": "python",
   "name": "llama2-clone"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
