{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcabab5c-9248-4393-b262-eafc68cd8ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install ipywidgets jupyter-ui-poll\n",
    "#!pip install llama-cpp-python langchain\n",
    "#!pip install style-bert-vits2 alkana\n",
    "#!pip install pandas black\n",
    "#!pip install google-api-python-client selenium beautifulsoup4 pdfplumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ed8c855-4eab-4fd6-8d95-2149dbff4a81",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/ex_ssd/envs/llama/lib/python3.10/site-packages/pyannote/audio/core/io.py:43: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.\n",
      "  torchaudio.set_audio_backend(\"soundfile\")\n"
     ]
    }
   ],
   "source": [
    "from warnings import simplefilter\n",
    "ignore_warnings = lambda : simplefilter('ignore')\n",
    "\n",
    "import os\n",
    "import llama_cpp\n",
    "import re\n",
    "import json\n",
    "import threading\n",
    "import asyncio\n",
    "from os import path\n",
    "\n",
    "# For ipywidgets.\n",
    "from IPython.display import clear_output, HTML\n",
    "from ipywidgets import widgets\n",
    "\n",
    "# my libs\n",
    "from lib.infrastructure import ForgetableContext, LlamaCpp, temporal_llama_cache\n",
    "from lib.uis import activate_cancel_ui, wait_for_change\n",
    "from lib.utils import now, mixed2katakana, get, fix_indentation\n",
    "from lib.infrastructure import LlamaInputIDManager\n",
    "\n",
    "# llama-cpp-python\n",
    "from llama_cpp import LlamaDiskCache\n",
    "\n",
    "# style-bert-vits2\n",
    "from style_bert_vits2.nlp import bert_models\n",
    "from style_bert_vits2.constants import Languages\n",
    "from style_bert_vits2.tts_model import TTSModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6071cf24-c40e-4c24-89b2-53dc8f1bd9d0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = LlamaCpp(\n",
    "    model_path=\"PATH_TO_YOUR_GGUF_FILE.gguf\",\n",
    "    n_gpu_layers=-1,\n",
    "    n_batch=1024,\n",
    "    n_ctx=8192,\n",
    "    use_mlock=True,\n",
    "    verbose=False,\n",
    "    embedding=False,\n",
    ")\n",
    "internal_llama = model.model.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "af2ad7d3-d6dc-4a76-8880-dbf77ffefee1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Globals.\n",
    "from lib.tools import MyPythonREPL\n",
    "\n",
    "DEFAULT_ASSISTANT_NAME = 'ãƒŸã‚¯'\n",
    "DEFAULT_USER_NICKNAME = 'ã›ã‚“ã›'\n",
    "\n",
    "MAXLEN = 70 \n",
    "assistant_name = DEFAULT_ASSISTANT_NAME\n",
    "user_nickname = DEFAULT_USER_NICKNAME\n",
    "context = ForgetableContext(maxlen=MAXLEN)\n",
    "py = MyPythonREPL(replace_nl=False, temporal_working_directory='agent_working_dir')\n",
    "login_time_stamp: str = \"\"\n",
    "\n",
    "# Event loop.\n",
    "loop = asyncio.get_event_loop()\n",
    "\n",
    "input_id_manager = LlamaInputIDManager(internal_llama)\n",
    "\n",
    "# style-bert-vits2\n",
    "tts_model: TTSModel|None = None\n",
    "\n",
    "# Set caches.\n",
    "main_cache = LlamaDiskCache(\".cache/cmr/main_cache\", 10*10e9) # 20GB\n",
    "agent_cache = LlamaDiskCache(\".cache/cmr/agent_cache\", 2*10e9) # 2GB\n",
    "\n",
    "# Use your own API_KEY and CSE_ID.\n",
    "GOOGLE_API_KEY = \"YOUR_GOOGLE_API_KEY\"\n",
    "GOOGLE_CSE_ID = \"YOUR_GOOGLE_CSE_ID\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "96e7c259-52ad-484d-bfb3-011026834579",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "internal_llama.cache = main_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "bfc26c39-1644-4ab4-bbb0-d8ef49897e2d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# GUIs.\n",
    "out = widgets.Output()\n",
    "debug = widgets.Output(layout=widgets.Layout(width='600px', height='100px', overflow='scroll'))\n",
    "field = widgets.Textarea(placeholder=f'ãƒ¦ãƒ¼ã‚¶ãƒ¼:', layout=widgets.Layout(width='490px', height='50px'))\n",
    "user_nickname_field = widgets.Text(description='AI->you', value=user_nickname, placeholder='Your nickname', layout=widgets.Layout(width='200px'))\n",
    "assistant_name_field = widgets.Text(description='You->AI', value=assistant_name, placeholder='Assistant name', layout=widgets.Layout(width='200px'))\n",
    "button = widgets.Button(description='ğŸ“¤', button_style='success', layout=widgets.Layout(width='50px', height='50px'))\n",
    "reset_button = widgets.Button(description='Reset', layout=widgets.Layout(width='120px'))\n",
    "retrieve = widgets.Button(description='Undo', layout=widgets.Layout(width='120px'))\n",
    "create_voice = widgets.Button(description='Synthesize voice', layout=widgets.Layout(width='120px'))\n",
    "buttons = [button, reset_button, retrieve, create_voice]\n",
    "voice_player = widgets.Output()\n",
    "dropdown: widgets.Dropdown|None = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f542ecf0-38fd-4648-8ff0-7a96fe714770",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Task pending name='Task-210' coro=<capture_model_selection_change() running at /var/folders/wz/g2cjflgj1g1bkvbnp4127h5h0000gn/T/ipykernel_91869/3237276757.py:33>>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TTS model loader\n",
    "\n",
    "\n",
    "def is_tts_model_dir(path):\n",
    "    if not os.path.isdir(path):\n",
    "        return False\n",
    "    files_to_check = [\n",
    "        f\"{os.path.basename(path)}.safetensors\",\n",
    "        \"config.json\",\n",
    "        \"style_vectors.npy\",\n",
    "    ]\n",
    "    folder_files = os.listdir(path)\n",
    "    return all(file in folder_files for file in files_to_check)\n",
    "\n",
    "\n",
    "\n",
    "@debug.capture()\n",
    "def load_tts_models(model_path):\n",
    "    import gc; gc.collect()\n",
    "    \n",
    "    bert_models.load_model(Languages.JP, \"ku-nlp/deberta-v2-large-japanese-char-wwm\")\n",
    "    bert_models.load_tokenizer(Languages.JP, \"ku-nlp/deberta-v2-large-japanese-char-wwm\")\n",
    "    \n",
    "    return TTSModel(\n",
    "        model_path=os.path.join(model_path, f\"{os.path.basename(model_path)}.safetensors\"),\n",
    "        config_path=os.path.join(model_path, \"config.json\"),\n",
    "        style_vec_path=os.path.join(model_path, \"style_vectors.npy\"),\n",
    "        device=\"cpu\"\n",
    "    )\n",
    "\n",
    "ASSET_ROOT = \"style_bert_vits2_models\"\n",
    "\n",
    "async def capture_model_selection_change():\n",
    "    global tts_model\n",
    "    while True:\n",
    "        selected = await wait_for_change(dropdown, \"value\")\n",
    "        tts_model = load_tts_models(os.path.join(ASSET_ROOT, selected))\n",
    "        debug.append_stdout(f\"tts_model({selected}) loaded.\")\n",
    "\n",
    "tts_model_names = [item for item in os.listdir(ASSET_ROOT) if is_tts_model_dir(os.path.join(ASSET_ROOT, item))]\n",
    "if len(tts_model_names) != 0:\n",
    "    tts_model = load_tts_models(os.path.join(ASSET_ROOT, tts_model_names[0]))\n",
    "dropdown = widgets.Dropdown(description=\"TTS model\", options=tts_model_names, value=tts_model_names[0]) if len(tts_model_names) != 0 else widgets.Dropdown(description=\"TTS model\", options=[])\n",
    "loop.create_task(capture_model_selection_change())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "da014e06-8893-48f8-8b16-5b761bb23210",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def reload_instruction():\n",
    "    global instructions\n",
    "    inst_file = 'notebooks/prompt_gen_13_cmr.txt'\n",
    "    with open(path.join(LLAMA_DIR, inst_file) , 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        instructions = ''.join(lines)\n",
    "\n",
    "reload_instruction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "fe39c86f-64d5-445f-b55d-6c6f5b100244",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def ctx2str(context, skip: int = 0) -> str:\n",
    "    \"\"\"ignore front items of number specified by 'skip'\"\"\"\n",
    "    text = ''\n",
    "    for item in context.context()[skip:]:\n",
    "        role = get(item, 'role')\n",
    "        content = get(item, 'content')\n",
    "        code = get(item, 'code')\n",
    "        code_output = get(item, 'code_output')\n",
    "        search_query = get(item, 'search_query')\n",
    "        search_result = get(item, 'search_result')\n",
    "\n",
    "        item_text = content\n",
    "\n",
    "        def add_block(block_name, block_content) -> str:\n",
    "            return \"\"\"\n",
    "```{block_name}\n",
    "{block_content}\n",
    "```\n",
    "\"\"\".format(block_name=block_name, block_content=block_content)\n",
    "        \n",
    "        if code: item_text += add_block(\"python\", code)\n",
    "        if code_output: item_text += add_block(\"output\", code_output)\n",
    "        if search_query: item_text += add_block(\"google\", search_query)\n",
    "        if search_result: item_text += add_block(\"result\", search_result)\n",
    "\n",
    "        text += {\n",
    "            assistant_name: f\"<|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>{item_text}<|END_OF_TURN_TOKEN|>\",\n",
    "            \"ãƒ¦ãƒ¼ã‚¶ãƒ¼\": f\"<|START_OF_TURN_TOKEN|><|USER_TOKEN|>{item_text}<|END_OF_TURN_TOKEN|>\",\n",
    "        }[role]\n",
    "        \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e78e503b-00ac-47ab-959f-a78a9d59b3df",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def export_log():\n",
    "    import datetime\n",
    "    global context\n",
    "    filename = str(datetime.datetime.now()).replace(' ', '_') + '.txt'\n",
    "    with open(f'log/{filename}', 'w') as f:\n",
    "       f.writelines(str(context))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9b8dd20d-0425-4212-a0eb-688a0e54a6b9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "tool_description = {\n",
    "    \"google\": \"æ¤œç´¢ãƒ¯ãƒ¼ãƒ‰ã‚’å¼•æ•°ã¨ã—ã¦googleæ¤œç´¢ã‚’è¡Œã†ã€‚ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æƒ…å ±ã‚’å¾—ã‚‹å ´åˆã«ã¯å¿…ãšã“ã®ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã€‚\",\n",
    "    \"python\": \"Pythonã‚³ãƒ¼ãƒ‰ã‚’è¨˜è¿°ãƒ»å®Ÿè¡Œã—ã¾ã™ã€‚ã‚³ãƒ¼ãƒ‰ã¯é©å®œæ”¹è¡Œã™ã‚‹ã“ã¨ã€‚å¤‰æ•°ã‚„é–¢æ•°ã¯ã‚»ãƒƒã‚·ãƒ§ãƒ³å†…ã§å…±æœ‰ã•ã‚Œã¾ã™ã€‚çµæœã¯å¿…ãšprintã‚ã‚‹ã„ã¯plt.show()ã§å‡ºåŠ›ã™ã‚‹ã“ã¨ã€‚\",\n",
    "}\n",
    "available_tools = list(tool_description.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6af74b50-de10-4906-b61c-6d7270448b15",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def compile_instruction(instructions):\n",
    "    return instructions.format(\n",
    "        now=login_time_stamp, \n",
    "        assistant=assistant_name, \n",
    "        user_nickname=user_nickname,\n",
    "        tool_names=available_tools,\n",
    "        tool_description='\\n'.join([f\"{name}: {description}\" for name, description in tool_description.items()]),\n",
    "    )\n",
    "\n",
    "def make_ppt(\n",
    "    instructions: str, \n",
    "    context,\n",
    "    skip: int = 0,\n",
    ") -> str:\n",
    "    # llama_cpp's tokenizer seems to add bos token automatically?\n",
    "    # https://gist.github.com/kohya-ss/37f4c5ef8171cbb2b6cc1f4fd7999b89\n",
    "    # instructions = \"<BOS_TOKEN>\" + instructions\n",
    "    return compile_instruction(instructions) + ctx2str(context, skip) + \"<|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6c51affe-1021-4400-826f-590292fc4d41",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def assistant_speaks(text) -> None:\n",
    "    global tts_model\n",
    "\n",
    "    if tts_model is None:\n",
    "        return\n",
    "    \n",
    "    def replace_text(text, replacement_dict):\n",
    "        for key, value in replacement_dict.items():\n",
    "            text = text.replace(key, value)\n",
    "        return text\n",
    "    \n",
    "    text = mixed2katakana(text)\n",
    "    text = re.sub(r'[(ï¼ˆ].*?[)ï¼‰]', 'ã€€', text)\n",
    "\n",
    "    text = replace_text(text, {\n",
    "        'ãˆã¸ã¸': 'ãˆã¸ã£',\n",
    "        'è¨€ã£ã¦': 'ã„ã£ã¦',\n",
    "        'â„ƒ': 'åº¦',\n",
    "        'kg': 'ã‚­ãƒ­',\n",
    "        'â™ª': 'ã€‚',\n",
    "        'ï¼š': 'ã€‚',\n",
    "        ':': 'ã€‚',\n",
    "    })\n",
    "    \n",
    "\n",
    "    try:\n",
    "        from IPython.display import Audio\n",
    "        if len(text) > 0:\n",
    "            with debug: sr, wav = tts_model.infer(text, length=1.15)\n",
    "        else:\n",
    "            return\n",
    "        audio = Audio(wav, rate=sr, autoplay=False)\n",
    "        voice_player.clear_output(wait=True)\n",
    "        with voice_player: display(audio)\n",
    "    except BaseException as e:\n",
    "        with debug: print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "aa7b5897-1729-4071-b334-6b3d92a3e8e6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# LangChain.agent\n",
    "\n",
    "ignore_warnings()\n",
    "\n",
    "from langchain.tools import Tool\n",
    "from lib.lang_chain_agent_cmr import create_agent_executor\n",
    "from lib.lang_chain_tools import GoogleSearchOpenable\n",
    "\n",
    "google = GoogleSearchOpenable(\n",
    "    n_results=3, \n",
    "    api_key=GOOGLE_API_KEY,\n",
    "    cse_id=GOOGLE_CSE_ID,\n",
    ")\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"google\", \n",
    "        description=\"æ¤œç´¢ãƒ¯ãƒ¼ãƒ‰ã‚’æŒ‡å®šã—ã€Webæ¤œç´¢ã‚’è¡Œã†ãƒ„ãƒ¼ãƒ«ã§ã™ã€‚æ¤œç´¢å¾Œã¯selectã§å„è¨˜äº‹ã‚’é–‹ãäº‹ãŒã§ãã¾ã™ã€‚\", \n",
    "        func=google.set\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"select\", \n",
    "        description=\"googleã§æ¤œç´¢ã—ãŸç•ªå·ã‚’Action Inputã«[æ¤œç´¢çµæœ1]ã®ã‚ˆã†ã«æŒ‡å®šã—ã¦ã€ãƒšãƒ¼ã‚¸ã‚’é–‹ãã¾ã™ã€‚\", \n",
    "        func=google.open\n",
    "    ),\n",
    "]\n",
    "\n",
    "agent_executor = create_agent_executor(\n",
    "    model, \n",
    "    tools, \n",
    "    max_iterations=6,\n",
    "    return_intermediate_steps=True,\n",
    "    model_kwargs={'temperature': 0.1, 'max_tokens': 1500},\n",
    ")\n",
    "\n",
    "@temporal_llama_cache(internal_llama, agent_cache)\n",
    "def exec_agent(model, request: str) -> tuple:\n",
    "    global google, agent_executor\n",
    "    def cleanup_agent_output(text: str) -> str:\n",
    "        return text.split('Question')[0].split('Thought')[0].strip()\n",
    "    \n",
    "    google.unset()\n",
    "    \n",
    "    response = agent_executor.invoke(request)\n",
    "    \n",
    "    output = cleanup_agent_output(response['output'])\n",
    "    ref = google.references()\n",
    "    \n",
    "    return output, ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c88b6aed-48f4-4597-bb6d-e9e3b95202fd",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def format_to_html(context) -> str:\n",
    "    def embed_image_to_tag(image_binary) -> str:\n",
    "        import base64\n",
    "        encoded_image = base64.b64encode(image_binary).decode('utf-8')\n",
    "        html_image_tag = f'<img src=\"data:image/jpeg;base64,{encoded_image}\" />'\n",
    "        return html_image_tag\n",
    "\n",
    "    def replace_charref(text) -> str:\n",
    "        return text.replace('<', '&lt;').replace('>', '&gt;').replace(' ', '&nbsp;')\n",
    "\n",
    "    messages: list[str] = []\n",
    "    for message in context.history():\n",
    "        role = message['role']\n",
    "        content = message['content']\n",
    "\n",
    "        name: str\n",
    "        text: str\n",
    "        text_template = \"\"\"<div style=\"background-color: {color}; word-wrap: break-word; color: black; padding: 10px; border-radius: 20px;\">{content}</div>\"\"\"\n",
    "        \n",
    "        if role == 'ãƒ¦ãƒ¼ã‚¶ãƒ¼':\n",
    "            content = replace_charref(content)\n",
    "            content = content.replace('\\n', '</br>')\n",
    "            text = text_template.format(content=content, color='#BBFFBB')\n",
    "            name = '<font color=#888888>ãƒ¦ãƒ¼ã‚¶ãƒ¼</font>'\n",
    "        elif role == assistant_name:\n",
    "            text =replace_charref(content)\n",
    "\n",
    "            references = get(message, 'references')\n",
    "            code = get(message, 'code')\n",
    "            code_output = get(message, 'code_output')\n",
    "            image_output = get(message, 'image_output')\n",
    "            search_result = get(message, 'search_result')\n",
    "            search_query = get(message, 'search_query')\n",
    "\n",
    "            if search_result:\n",
    "                text += '<div style=\"background-color: #999999; color: black;\">' + f'æ¤œç´¢(query=\"{search_query}\")' + '</div>'\n",
    "                text += '<div style=\"background-color: #FFFFFF; color: black;\">' + search_result + '</div>'\n",
    "            if references:\n",
    "                text += '<div style=\"background-color: #999999; color: black;\">å‚è€ƒ</div>'\n",
    "                text += '<div style=\"background-color: #FFFFFF; color: black;\">' + ''.join([f'<a href=\"{url}\">âš«ï¸</a>' for url in references]) + '</div>'\n",
    "            if code:\n",
    "                header = '<div style=\"background-color: #999999; color: black;\">{text}</div>'\n",
    "                text += header.format(text='Python')\n",
    "                text += '<pre><code>' + code + '</code></pre>'\n",
    "                text += header.format(text='Output')\n",
    "                text += '<pre><code>' + (code_output if code_output else 'Empty stdout/stderr.') + '</code></pre>'\n",
    "            if image_output:\n",
    "                text += '</br>' + embed_image_to_tag(image_binary=image_output) + '</br>'\n",
    "\n",
    "            # Other code blocks.\n",
    "            regex = re.compile(r'```(\\w+)?[ \\n](.*?)\\n?```', re.DOTALL)\n",
    "            text = re.sub(\n",
    "                regex, \n",
    "                r'<div style=\"background-color: #999999; color: black;\">\\1</div><pre><code>\\2</code></pre>', \n",
    "                text\n",
    "            )\n",
    "            \n",
    "            \n",
    "            text = text.replace('\\n', '</br>')\n",
    "            text = text_template.format(content=text, color='#FFEEBB')\n",
    "            name = f'<font color=#888888><div style=\"text-align:right\">{role}</div></font>'\n",
    "        \n",
    "        messages.append(f'{name}{text}')\n",
    "        \n",
    "    return ''.join(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "14a8ca55-49b7-4807-a983-9f052bcc4dff",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def print_context():\n",
    "    global context\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    html_text=\"\"\"<!DOCTYPE html>\n",
    "<html>\n",
    "\n",
    "<head>\n",
    "  <meta charset=\"utf-8\" />\n",
    "  <style>\n",
    "    #wrapper {{\n",
    "      display: flex;\n",
    "      flex-direction: column-reverse;\n",
    "      height: 1600px;\n",
    "      width: 800px;\n",
    "      overflow-y: scroll;\n",
    "    }}\n",
    "\n",
    "    /* Custom Scrollbar CSS */\n",
    "    #wrapper::-webkit-scrollbar {{\n",
    "      width: 10px;\n",
    "    }}\n",
    "\n",
    "    #wrapper::-webkit-scrollbar-track {{\n",
    "      background: #f1f1f1;\n",
    "    }}\n",
    "\n",
    "    #wrapper::-webkit-scrollbar-thumb {{\n",
    "      background: #888;\n",
    "    }}\n",
    "\n",
    "    #wrapper::-webkit-scrollbar-thumb:hover {{\n",
    "      background: #555;\n",
    "    }}\n",
    "    \n",
    "  </style>\n",
    "</head>\n",
    "\n",
    "<body>\n",
    "    <div style=\"display: flex; align-items: flex-end;\">\n",
    "      <div id=\"wrapper\">\n",
    "        <div id=\"contents\">\n",
    "    {content}\n",
    "        </div>\n",
    "      </div>\n",
    "    </div>\n",
    "</body>\n",
    "\n",
    "</html>\n",
    "\"\"\"\n",
    "    html_text = html_text.format(\n",
    "        content=format_to_html(context), \n",
    "    )\n",
    "\n",
    "    display(HTML(html_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b0cd38fd-d984-4caf-b8ae-56f0eee6cf73",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "guessing_image: widgets.Image\n",
    "\n",
    "with open('guessing.gif', 'rb') as f:\n",
    "    guessing_image = widgets.Image(value=f.read(), width=50, height=50)\n",
    "\n",
    "def set_guessing_image(show: bool) -> None:\n",
    "    global guessing_image\n",
    "    with open('guessing.gif' if show else 'empty.png', 'rb') as f:\n",
    "        guessing_image.value = f.read() \n",
    "        guessing_image.width = 50\n",
    "        guessing_image.height = 50\n",
    "\n",
    "set_guessing_image(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ed7b25fa-acdf-4ba4-9522-ea8979e90ff7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def set_buttons(disabled: bool) -> None:\n",
    "    global buttons\n",
    "    for b in buttons:\n",
    "        b.disabled = disabled\n",
    "\n",
    "def disable_uis(func):\n",
    "    from functools import wraps\n",
    "    @wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        set_buttons(disabled=True)\n",
    "        set_guessing_image(True)\n",
    "        result = func(*args, **kwargs)\n",
    "        set_guessing_image(False)\n",
    "        set_buttons(disabled=False)\n",
    "        return result\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "96546328-7fa7-4fa8-9e6e-5a0b4a441bdb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def initialize(sender=None) -> None:\n",
    "    global context, field, assistant_name_field, user_nickname_field, login_time_stamp\n",
    "\n",
    "    context.reset()\n",
    "    field.value = ''\n",
    "    user_nickname_field.disabled = False\n",
    "    assistant_name_field.disabled = False\n",
    "    login_time_stamp = now()\n",
    "    \n",
    "    with out:\n",
    "        print_context()\n",
    "\n",
    "    from IPython.display import Audio\n",
    "    voice_player.clear_output(wait=True)\n",
    "    with voice_player:\n",
    "        display(Audio(b''))\n",
    "\n",
    "initialize()\n",
    "\n",
    "def submit_names_action(sender=None) -> None:\n",
    "    global user_nickname, user_nickname_field, assistant_name, assistant_name_field\n",
    "\n",
    "    user_nickname = user_nickname_field.value\n",
    "    assistant_name = assistant_name_field.value\n",
    "    user_nickname_field.disabled = True\n",
    "    assistant_name_field.disabled = True\n",
    "\n",
    "@out.capture()\n",
    "def retrieve_latest_input(sender = None):\n",
    "    global field, context\n",
    "\n",
    "    if len(context) <= 0:\n",
    "        field.value = ''\n",
    "        print_context()\n",
    "        return\n",
    "\n",
    "    last_item = context.force_pop_front(stringize=False)\n",
    "    if last_item['role'] == 'ãƒ¦ãƒ¼ã‚¶ãƒ¼':\n",
    "        field.value = last_item['content']\n",
    "    print_context()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a5e7adfb-b249-48e4-8089-ad4b115b1a7e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def force_save_state():\n",
    "    global internal_llama\n",
    "    prompt = make_ppt(instructions, context)\n",
    "    prompt_tokens = ((internal_llama.tokenize(prompt.encode(\"utf-8\"), special=True)))\n",
    "    #\n",
    "    # save to main_cache\n",
    "    # using prompt_tokens(+completion_tokens) as key of the cache depends on implementation of llama_cpp's _create_complesion.\n",
    "    # The code: https://github.com/abetlen/llama-cpp-python/blob/main/llama_cpp/llama.py#L954 \n",
    "    #\n",
    "    internal_llama.cache[prompt_tokens] = internal_llama.save_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a363299d-8084-4800-ab11-623761e4e87e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def predict_stream(additional_stop_tokens: list[str] = []):\n",
    "    global model, instructions, context\n",
    "\n",
    "    prompt = make_ppt(instructions, context)\n",
    "    \n",
    "    streamer = model.stream(\n",
    "        input=prompt,\n",
    "        temperature=0.2,\n",
    "        max_tokens=1500,\n",
    "        stop=additional_stop_tokens\n",
    "    )\n",
    "\n",
    "    pattern = re.compile(\n",
    "        r'(.*?```\\n?({tools}).*?```)'.format(tools='|'.join(available_tools)), \n",
    "        re.DOTALL\n",
    "    )\n",
    "\n",
    "    output = ''\n",
    "    for token in streamer:\n",
    "        output += token\n",
    "        \n",
    "        match = re.search(pattern, output)\n",
    "        if match:\n",
    "            output = match.group(1)\n",
    "            yield output\n",
    "            # Because of break, token generation doesn't complete properly.\n",
    "            # The inproper interruption results in no activation of diskcache saving that normally happens after completion.\n",
    "            # So, we need to add code to force saving LlamaState.\n",
    "            force_save_state()\n",
    "            break \n",
    "        else:\n",
    "            yield output.strip()\n",
    "        \n",
    "        \n",
    "\n",
    "def predict_stream_with_display(additional_stop_tokens: list[str] = []):\n",
    "    with debug:\n",
    "        for output in predict_stream(additional_stop_tokens):\n",
    "            context.push_message(assistant_name, output)\n",
    "            with out: print_context()\n",
    "            context.force_pop_front()\n",
    "            \n",
    "    context.push_message(assistant_name, output)\n",
    "    with out: print_context()\n",
    "    context.force_pop_front()\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4554cb9b-b3ae-4a67-8d0c-46e522f7be5e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def message_chain(reply):\n",
    "    global assistant_name, model, context\n",
    "    context.push_message(assistant_name, reply)\n",
    "    with out: print_context()\n",
    "\n",
    "\n",
    "def python_chain(python_code):\n",
    "\n",
    "    # Reformat code.\n",
    "    import black\n",
    "    python_code = fix_indentation(python_code)\n",
    "    try: python_code = black.format_str(python_code, mode=black.Mode())\n",
    "    except: pass\n",
    "    \n",
    "    # Run code.\n",
    "    py.unset(keep_locals=True)\n",
    "    py.run(python_code)\n",
    "    code, code_output, image_output = py.result()\n",
    "\n",
    "    # Register into context.\n",
    "    last_item = context.force_pop_front(stringize=False)\n",
    "    last_item['code'] = code\n",
    "    last_item['code_output'] = code_output if code_output else \"Empty stdout/stderr.\"\n",
    "    last_item['image_output'] = image_output\n",
    "    context.push(last_item)\n",
    "    with out: print_context()\n",
    "\n",
    "    # Add reaction to the execution results.\n",
    "    reply = predict_stream_with_display(additional_stop_tokens=[\"```\"])\n",
    "    context.push_message(assistant_name, reply)\n",
    "    with out: print_context()\n",
    "\n",
    "\n",
    "\n",
    "def search_chain(search_query):\n",
    "    global context, assistant_name, model\n",
    "\n",
    "    # Show confirmation of search to the user.\n",
    "    context.push_message(assistant_name, 'ğŸ”ã€Œ' + search_query + 'ã€ã§æ¤œç´¢ã—ã¾ã™ã€‚')\n",
    "    with out: print_context()\n",
    "    with out: cancel = activate_cancel_ui(wait_sec=10)\n",
    "    if cancel:\n",
    "        retrieve_latest_input()\n",
    "        return\n",
    "\n",
    "    \n",
    "    # Register search result to the context.\n",
    "    with out: print_context()\n",
    "    with debug:\n",
    "        search_result, referred_urls = exec_agent(model, f'\"{search_query}\"ã§æ¤œç´¢ã—ã¦å†…å®¹ã‚’ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚æ¤œç´¢ãƒ¯ãƒ¼ãƒ‰ã¯æŒ‡ç¤ºé€šã‚Šã¨ã—ã€å¤‰æ›´ã—ã¦ã¯ã„ã‘ã¾ã›ã‚“ã€‚ãµãŸã¤ã¯æ¤œç´¢çµæœã‚’é–‹ãå†…å®¹ã‚’ç¢ºèªã™ã‚‹ã“ã¨ã€‚')\n",
    "    context.force_pop_front()\n",
    "    last_item = context.force_pop_front(stringize=False)\n",
    "    last_item['search_query'] = search_query\n",
    "    last_item['search_result'] = search_result\n",
    "    last_item['references'] = referred_urls\n",
    "    context.push(last_item)\n",
    "    with out: print_context()\n",
    "\n",
    "    \n",
    "    # Add reaction to the search results.\n",
    "    reply = predict_stream_with_display(additional_stop_tokens=[\"```\"])\n",
    "    context.push_message(assistant_name, reply)\n",
    "    with out: print_context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "df533939-2566-4e73-ae24-f936d65bf9d7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Main loop.\n",
    "@disable_uis\n",
    "def main(sender=None) -> None:\n",
    "    global  context, field, submit_names\n",
    "\n",
    "    submit_names_action()\n",
    "\n",
    "    user_message = field.value\n",
    "    if user_message != '':\n",
    "        field.value = ''\n",
    "        context.push_message('ãƒ¦ãƒ¼ã‚¶ãƒ¼', user_message)\n",
    "    with out: print_context()\n",
    "        \n",
    "    output = predict_stream_with_display()\n",
    "\n",
    "    # Parse tool.\n",
    "    regex = re.compile(\n",
    "        r'```({tools})(.*)```'.format(tools='|'.join(available_tools)), \n",
    "        re.DOTALL\n",
    "    )\n",
    "    tool = re.search(regex, output)\n",
    "\n",
    "    # Remove tool tags.\n",
    "    cleaned_output = re.sub(regex, '', output).rstrip()\n",
    "    message_chain(cleaned_output)\n",
    "    \n",
    "    # Passing to extra chain.\n",
    "    if tool:\n",
    "        tool_type, tool_input = tool.group(1), tool.group(2).strip()\n",
    "        {\n",
    "            'python': python_chain,\n",
    "            'google': search_chain,\n",
    "        }[tool_type](tool_input)\n",
    "\n",
    "    export_log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "61fb2c28-48be-4302-b8d7-64b9710b34fd",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "@disable_uis\n",
    "def create_voice_action(sender=None):\n",
    "    try:\n",
    "        text = get(context.history()[-1], \"content\")\n",
    "        assistant_speaks(text)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "3547323b-eed7-43dd-973f-812718ecf408",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Define UI actions.\n",
    "button.on_click(main)\n",
    "reset_button.on_click(initialize)\n",
    "retrieve.on_click(retrieve_latest_input)\n",
    "create_voice.on_click(create_voice_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e9aae6c7-1574-4a98-892d-86eadd19773a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def show_guis() -> None:\n",
    "    html = \"\"\"<h2>{default_name}ã¡ã‚ƒã‚“ã¨ãŠã—ã‚ƒã¹ã‚Š!(ä»®)</h2>\n",
    "ãŠã—ã‚ƒã¹ã‚Šã‚„ã‚¦ã‚§ãƒ–æ¤œç´¢ãƒ»Pythonå®Ÿè¡Œã‚’åˆ©ç”¨ã—ãŸQ&AãŒã§ãã¾ã™ã€‚</br>\n",
    "agent_working_dir: Pythonå®Ÿè¡Œæ™‚ã®ãƒ¯ãƒ¼ã‚­ãƒ³ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã€‚</br>\n",
    "style_bert_vits2_models: TTSãƒ¢ãƒ‡ãƒ«ã‚’å…¥ã‚Œã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã€‚</br>\n",
    "(ãƒ¢ãƒ‡ãƒ«ã®ã‚ã‚‹ã‚µãƒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªåã¨.safetensorsã®åå‰ã¯ä¸€è‡´ã—ã¦ã„ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™)</br>\n",
    "</br>\n",
    "\"\"\".format(default_name=DEFAULT_ASSISTANT_NAME)\n",
    "    HBox = widgets.HBox\n",
    "    display(\n",
    "        HTML(html),\n",
    "        HBox([user_nickname_field, assistant_name_field]),\n",
    "        out,\n",
    "        HBox([field, button, guessing_image]),\n",
    "        HBox([retrieve, reset_button, create_voice]),\n",
    "        dropdown,\n",
    "        voice_player,\n",
    "        debug,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "aabea719-a638-4107-be1f-bfa26321fbac",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2>ãƒŸã‚¯ã¡ã‚ƒã‚“ã¨ãŠã—ã‚ƒã¹ã‚Š!(ä»®)</h2>\n",
       "ãŠã—ã‚ƒã¹ã‚Šã‚„ã‚¦ã‚§ãƒ–æ¤œç´¢ãƒ»Pythonå®Ÿè¡Œã‚’åˆ©ç”¨ã—ãŸQ&AãŒã§ãã¾ã™ã€‚</br>\n",
       "agent_working_dir: Pythonå®Ÿè¡Œæ™‚ã®ãƒ¯ãƒ¼ã‚­ãƒ³ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã€‚</br>\n",
       "style_bert_vits2_models: TTSãƒ¢ãƒ‡ãƒ«ã‚’å…¥ã‚Œã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã€‚</br>\n",
       "(ãƒ¢ãƒ‡ãƒ«ã®ã‚ã‚‹ã‚µãƒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªåã¨.safetensorsã®åå‰ã¯ä¸€è‡´ã—ã¦ã„ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™)</br>\n",
       "</br>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "914a854b310046479006b4e5e0798ebb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Text(value='ã›ã‚“ã›', description='AI->you', layout=Layout(width='200px'), placeholder='Your nicknaâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfd970bbca724c969384fcaa6ed13bc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b638af1860944d5bcbf86c3e370b54c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Textarea(value='', layout=Layout(height='50px', width='490px'), placeholder='ãƒ¦ãƒ¼ã‚¶ãƒ¼:'), Button(buâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd8bb894b3944326b815abb1a9e3158b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(description='Undo', layout=Layout(width='120px'), style=ButtonStyle()), Button(descriptiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10b565d4257c460caa8dce32c13f821b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='TTS model', options=(), value=None)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e68e2c18e1643ef9e57ba0916e20721",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc2daa16d55245d0a8c139b8a6f53726",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(height='100px', overflow='scroll', width='600px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ignore_warnings()\n",
    "show_guis()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama",
   "language": "python",
   "name": "llama"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
